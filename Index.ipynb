{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Jupyter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyimagesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3fddb53b57cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyimagesearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfour_point_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold_local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyimagesearch'"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyimagesearch.transform import four_point_transform\n",
    "from skimage.filters import threshold_local\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.ndimage.filters import rank_filter\n",
    "\n",
    "\n",
    "\n",
    "def dilate(ary, N, iterations): \n",
    "\t\"\"\"Dilate using an NxN '+' sign shape. ary is np.uint8.\"\"\"\n",
    "\t\n",
    "\tkernel = np.zeros((N,N), dtype=np.uint8)\n",
    "\tkernel[(N-1)//2,:] = 1  # Bug solved with // (integer division)\n",
    "\t\n",
    "\tdilated_image = cv2.dilate(ary / 255, kernel, iterations=iterations)\n",
    "\t\n",
    "\tkernel = np.zeros((N,N), dtype=np.uint8)\n",
    "\tkernel[:,(N-1)//2] = 1  # Bug solved with // (integer division)\n",
    "\tdilated_image = cv2.dilate(dilated_image, kernel, iterations=iterations)\n",
    "\treturn dilated_image\n",
    "\n",
    "\n",
    "def props_for_contours(contours, ary):\n",
    "\t\"\"\"Calculate bounding box & the number of set pixels for each contour.\"\"\"\n",
    "\tc_info = []\n",
    "\tfor c in contours:\n",
    "\t\tx,y,w,h = cv2.boundingRect(c)\n",
    "\t\tc_im = np.zeros(ary.shape)\n",
    "\t\tcv2.drawContours(c_im, [c], 0, 255, -1)\n",
    "\t\tc_info.append({\n",
    "\t\t\t'x1': x,\n",
    "\t\t\t'y1': y,\n",
    "\t\t\t'x2': x + w - 1,\n",
    "\t\t\t'y2': y + h - 1,\n",
    "\t\t\t'sum': np.sum(ary * (c_im > 0))/255\n",
    "\t\t})\n",
    "\treturn c_info\n",
    "\n",
    "\n",
    "def union_crops(crop1, crop2):\n",
    "\t\"\"\"Union two (x1, y1, x2, y2) rects.\"\"\"\n",
    "\tx11, y11, x21, y21 = crop1\n",
    "\tx12, y12, x22, y22 = crop2\n",
    "\treturn min(x11, x12), min(y11, y12), max(x21, x22), max(y21, y22)\n",
    "\n",
    "\n",
    "def intersect_crops(crop1, crop2):\n",
    "\tx11, y11, x21, y21 = crop1\n",
    "\tx12, y12, x22, y22 = crop2\n",
    "\treturn max(x11, x12), max(y11, y12), min(x21, x22), min(y21, y22)\n",
    "\n",
    "\n",
    "def crop_area(crop):\n",
    "\tx1, y1, x2, y2 = crop\n",
    "\treturn max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "\n",
    "def find_border_components(contours, ary):\n",
    "\tborders = []\n",
    "\tarea = ary.shape[0] * ary.shape[1]\n",
    "\tfor i, c in enumerate(contours):\n",
    "\t\tx,y,w,h = cv2.boundingRect(c)\n",
    "\t\tif w * h > 0.5 * area:\n",
    "\t\t\tborders.append((i, x, y, x + w - 1, y + h - 1))\n",
    "\treturn borders\n",
    "\n",
    "\n",
    "def angle_from_right(deg):\n",
    "\treturn min(deg % 90, 90 - (deg % 90))\n",
    "\n",
    "\n",
    "def remove_border(contour, ary):\n",
    "\t\"\"\"Remove everything outside a border contour.\"\"\"\n",
    "\t# Use a rotated rectangle (should be a good approximation of a border).\n",
    "\t# If it's far from a right angle, it's probably two sides of a border and\n",
    "\t# we should use the bounding box instead.\n",
    "\tc_im = np.zeros(ary.shape)\n",
    "\tr = cv2.minAreaRect(contour)\n",
    "\tdegs = r[2]\n",
    "\tif angle_from_right(degs) <= 10.0:\n",
    "\t\tbox = cv2.boxPoints(r)\n",
    "\t\tbox = np.int0(box)\n",
    "\t\tcv2.drawContours(c_im, [box], 0, 255, -1)\n",
    "\t\tcv2.drawContours(c_im, [box], 0, 0, 4)\n",
    "\telse:\n",
    "\t\tx1, y1, x2, y2 = cv2.boundingRect(contour)\n",
    "\t\tcv2.rectangle(c_im, (x1, y1), (x2, y2), 255, -1)\n",
    "\t\tcv2.rectangle(c_im, (x1, y1), (x2, y2), 0, 4)\n",
    "\n",
    "\treturn np.minimum(c_im, ary)\n",
    "\n",
    "\n",
    "def find_components(edges, max_components=16):\n",
    "\t\"\"\"Dilate the image until there are just a few connected components.\n",
    "\n",
    "\tReturns contours for these components.\"\"\"\n",
    "\t# Perform increasingly aggressive dilation until there are just a few\n",
    "\t# connected components.\n",
    "\t\n",
    "\tcount = 21\n",
    "\tdilation = 5\n",
    "\tn = 1\n",
    "\twhile count > 16:\n",
    "\t\tn += 1\n",
    "\t\tdilated_image = dilate(edges, N=3, iterations=n)\n",
    "\t\tdilated_image = np.uint8(dilated_image)\n",
    "\t\tcontours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tcount = len(contours)\n",
    "\t#print dilation\n",
    "\t#Image.fromarray(edges).show()\n",
    "\t#Image.fromarray(255 * dilated_image).show()\n",
    "\treturn contours\n",
    "\n",
    "\n",
    "def find_optimal_components_subset(contours, edges):\n",
    "\t\"\"\"Find a crop which strikes a good balance of coverage/compactness.\n",
    "\n",
    "\tReturns an (x1, y1, x2, y2) tuple.\n",
    "\t\"\"\"\n",
    "\tc_info = props_for_contours(contours, edges)\n",
    "\tc_info.sort(key=lambda x: -x['sum'])\n",
    "\ttotal = np.sum(edges) / 255\n",
    "\tarea = edges.shape[0] * edges.shape[1]\n",
    "\n",
    "\tc = c_info[0]\n",
    "\tdel c_info[0]\n",
    "\tthis_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "\tcrop = this_crop\n",
    "\tcovered_sum = c['sum']\n",
    "\n",
    "\twhile covered_sum < total:\n",
    "\t\tchanged = False\n",
    "\t\trecall = 1.0 * covered_sum / total\n",
    "\t\tprec = 1 - 1.0 * crop_area(crop) / area\n",
    "\t\tf1 = 2 * (prec * recall / (prec + recall))\n",
    "\t\t#print '----'\n",
    "\t\tfor i, c in enumerate(c_info):\n",
    "\t\t\tthis_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "\t\t\tnew_crop = union_crops(crop, this_crop)\n",
    "\t\t\tnew_sum = covered_sum + c['sum']\n",
    "\t\t\tnew_recall = 1.0 * new_sum / total\n",
    "\t\t\tnew_prec = 1 - 1.0 * crop_area(new_crop) / area\n",
    "\t\t\tnew_f1 = 2 * new_prec * new_recall / (new_prec + new_recall)\n",
    "\n",
    "\t\t\t# Add this crop if it improves f1 score,\n",
    "\t\t\t# _or_ it adds 25% of the remaining pixels for <15% crop expansion.\n",
    "\t\t\t# ^^^ very ad-hoc! make this smoother\n",
    "\t\t\tremaining_frac = c['sum'] / (total - covered_sum)\n",
    "\t\t\tnew_area_frac = 1.0 * crop_area(new_crop) / crop_area(crop) - 1\n",
    "\t\t\tif new_f1 > f1 or (\n",
    "\t\t\t\t\tremaining_frac > 0.25 and new_area_frac < 0.15):\n",
    "\t\t\t\tprint('%d %s -> %s / %s (%s), %s -> %s / %s (%s), %s -> %s' % (\n",
    "\t\t\t\t\t\ti, covered_sum, new_sum, total, remaining_frac,\n",
    "\t\t\t\t\t\tcrop_area(crop), crop_area(new_crop), area, new_area_frac,\n",
    "\t\t\t\t\t\tf1, new_f1))\n",
    "\t\t\t\tcrop = new_crop\n",
    "\t\t\t\tcovered_sum = new_sum\n",
    "\t\t\t\tdel c_info[i]\n",
    "\t\t\t\tchanged = True\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tif not changed:\n",
    "\t\t\tbreak\n",
    "\n",
    "\treturn crop\n",
    "\n",
    "\n",
    "def pad_crop(crop, contours, edges, border_contour, pad_px=15):\n",
    "\t\"\"\"Slightly expand the crop to get full contours.\n",
    "\n",
    "\tThis will expand to include any contours it currently intersects, but will\n",
    "\tnot expand past a border.\n",
    "\t\"\"\"\n",
    "\tbx1, by1, bx2, by2 = 0, 0, edges.shape[0], edges.shape[1]\n",
    "\tif border_contour is not None and len(border_contour) > 0:\n",
    "\t\tc = props_for_contours([border_contour], edges)[0]\n",
    "\t\tbx1, by1, bx2, by2 = c['x1'] + 5, c['y1'] + 5, c['x2'] - 5, c['y2'] - 5\n",
    "\n",
    "\tdef crop_in_border(crop):\n",
    "\t\tx1, y1, x2, y2 = crop\n",
    "\t\tx1 = max(x1 - pad_px, bx1)\n",
    "\t\ty1 = max(y1 - pad_px, by1)\n",
    "\t\tx2 = min(x2 + pad_px, bx2)\n",
    "\t\ty2 = min(y2 + pad_px, by2)\n",
    "\t\treturn crop\n",
    "\t\n",
    "\tcrop = crop_in_border(crop)\n",
    "\n",
    "\tc_info = props_for_contours(contours, edges)\n",
    "\tchanged = False\n",
    "\tfor c in c_info:\n",
    "\t\tthis_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "\t\tthis_area = crop_area(this_crop)\n",
    "\t\tint_area = crop_area(intersect_crops(crop, this_crop))\n",
    "\t\tnew_crop = crop_in_border(union_crops(crop, this_crop))\n",
    "\t\tif 0 < int_area < this_area and crop != new_crop:\n",
    "\t\t\tprint('%s -> %s' % (str(crop), str(new_crop)))\n",
    "\t\t\tchanged = True\n",
    "\t\t\tcrop = new_crop\n",
    "\n",
    "\tif changed:\n",
    "\t\treturn pad_crop(crop, contours, edges, border_contour, pad_px)\n",
    "\telse:\n",
    "\t\treturn crop\n",
    "\n",
    "\n",
    "def downscale_image(im, max_dim=2048):\n",
    "\t\"\"\"Shrink im until its longest dimension is <= max_dim.\n",
    "\n",
    "\tReturns new_image, scale (where scale <= 1).\n",
    "\t\"\"\"\n",
    "\ta, b = im.size\n",
    "\tif max(a, b) <= max_dim:\n",
    "\t\treturn 1.0, im\n",
    "\n",
    "\tscale = 1.0 * max_dim / max(a, b)\n",
    "\tnew_im = im.resize((int(a * scale), int(b * scale)), Image.ANTIALIAS)\n",
    "\treturn scale, new_im\n",
    "\n",
    "\n",
    "def process_image(path, out_path):\n",
    "\n",
    "\torig_im = Image.open(path)\n",
    "\tscale, im = downscale_image(orig_im)\n",
    "\n",
    "\tedges = cv2.Canny(np.asarray(im), 100, 200)\n",
    "\n",
    "\t# TODO: dilate image _before_ finding a border. This is crazy sensitive!\n",
    "\tcontours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tborders = find_border_components(contours, edges)\n",
    "\tborders.sort(key=lambda i_x1_y1_x2_y2: (i_x1_y1_x2_y2[3] - i_x1_y1_x2_y2[1]) * (i_x1_y1_x2_y2[4] - i_x1_y1_x2_y2[2]))\n",
    "\n",
    "\tborder_contour = None\n",
    "\tif len(borders):\n",
    "\t\tborder_contour = contours[borders[0][0]]\n",
    "\t\tedges = remove_border(border_contour, edges)\n",
    "\n",
    "\tedges = 255 * (edges > 0).astype(np.uint8)\n",
    "\n",
    "\t# Remove ~1px borders using a rank filter.\n",
    "\tmaxed_rows = rank_filter(edges, -4, size=(1, 20))\n",
    "\tmaxed_cols = rank_filter(edges, -4, size=(20, 1))\n",
    "\tdebordered = np.minimum(np.minimum(edges, maxed_rows), maxed_cols)\n",
    "\tedges = debordered\n",
    "\n",
    "\tcontours = find_components(edges)\n",
    "\tif len(contours) == 0:\n",
    "\t\tprint('%s -> (no text!)' % path)\n",
    "\t\treturn\n",
    "\n",
    "\t\n",
    "\n",
    "\tcrop = find_optimal_components_subset(contours, edges)\n",
    "\tcrop = pad_crop(crop, contours, edges, border_contour)\n",
    "\n",
    "\tcrop = [int(x / scale) for x in crop]  # upscale to the original image size.\n",
    "\n",
    "\t#draw = ImageDraw.Draw(im)\n",
    "\t#c_info = props_for_contours(contours, edges)\n",
    "\t#for c in c_info:\n",
    "\t#    this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "\t#    draw.rectangle(this_crop, outline='blue')\n",
    "\t#draw.rectangle(crop, outline='red')\n",
    "\t#im.save(out_path)\n",
    "\t#draw.text((50, 50), path, fill='red')\n",
    "\t#orig_im.save(out_path)\n",
    "\t#im.show()\n",
    "\ttext_im = orig_im.crop(crop)\n",
    "\ttext_im.save(out_path)\n",
    "\tprint('%s -> %s' % (path, out_path))\n",
    "\n",
    "\n",
    "\n",
    "def crop_morphology(path):\n",
    "\tout_path = path.replace('.jpg', '.crop.png')\n",
    "\t#out_path = path.replace('.png', '.crop.png')  # .png as input\n",
    "\tif not os.path.exists(path):\n",
    "\t\tprint(\"Given path does not exist. Aborting\")\n",
    "\t\treturn False\n",
    "\ttry:\n",
    "\t\tprocess_image(path, out_path)\n",
    "\t\treturn True\n",
    "\texcept Exception as e:\n",
    "\t\tprint('%s %s' % (path, e))\n",
    "\t\treturn False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################################################\n",
    "\n",
    "# USAGE\n",
    "# python scan.py --image images/page.jpg\n",
    "\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required = True,\n",
    "\thelp = \"Path to the image to be scanned\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the image and compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "\n",
    "dirname = 'Scanned_Images'\n",
    "os.mkdir(dirname)\n",
    "image = cv2.imread(args[\"image\"],0)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(image)\n",
    "cv2.imwrite('clahe_2.jpg',cl1)\n",
    "\n",
    "\n",
    "image = cv2.imread('clahe_2.jpg')\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    "\n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# show the original image and the edge detected image\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "#cv2.imshow(\"Image\", image)\n",
    "#cv2.imshow(\"Edged\", edged)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "\t# if our approximated contour has four points, then we\n",
    "\t# can assume that we have found our screen\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\t# show the contour (outline) of the piece of paper\n",
    "\t\tprint(\"STEP 2: Find contours of paper\")\n",
    "\t\tcv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "\t\t#cv2.imshow(\"Outline\", image)\n",
    "\t\t\n",
    "\n",
    "\t\t# apply the four point transform to obtain a top-down\n",
    "\t\t# view of the original image\n",
    "\t\twarped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "\t\t# convert the warped image to grayscale, then threshold it\n",
    "\t\t# to give it that 'black and white' paper effect\n",
    "\t\twarped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "\t\tT = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "\t\twarped = (warped > T).astype(\"uint8\") * 255\n",
    "\n",
    "\t\tkernel = np.ones((3,3),np.uint8)\n",
    "\t\twarped = cv2.erode(warped,kernel,iterations = 1)\n",
    "\n",
    "\t\t# show the original and scanned images\n",
    "\t\tprint(\"STEP 3: Apply perspective transform\")\n",
    "\t\t\n",
    "\t\tcv2.imwrite(os.path.join(dirname , 'Scanned.jpg'), warped)\n",
    "\t\t\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\t#input = clahe_2.jpg.  to the sript file output= image\n",
    "\t#\tclahe_2 = cv2.imread('clahe_2.jpg',0)\n",
    "\t#\tclahe_2 = cv2.GaussianBlur(clahe_2, (5, 5), 0)\n",
    "\t\t\n",
    "\t\t#cv2.imwrite('clahe_2_blur.jpg',clahe_2)\n",
    "\t\t#print('running')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tclahe_2_simple = cv2.imread('clahe_2.jpg',0)\n",
    "\t\tcv2.imwrite('clahe_2_simple_blur.jpg',clahe_2_simple)\n",
    "\t\t#WHEN LIGHTING IS DIM\n",
    "\t\tclahe_2_blur = cv2.GaussianBlur(clahe_2_simple, (5, 5), 0)\n",
    "\t\tcv2.imwrite('clahe_2_blur_blur.jpg',clahe_2_blur)\n",
    "\t\t#WHEN OTHER FACTOR DIMINISHES THE IMAGE QUALITY\n",
    "\t\tkernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\t\tclahe_2_sharp = cv2.filter2D(clahe_2_simple, -1, kernel_sharpening)\n",
    "\t\tcv2.imwrite('clahe_2_sharp_blur.jpg',clahe_2_sharp)\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tif(crop_morphology('clahe_2_simple_blur.jpg')):\n",
    "\t\t\timage=cv2.imread(\"clahe_2_simple_blur.crop.png\")\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tret1,image1 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "\t\t\n",
    "\t\t\tcv2.imwrite(os.path.join(dirname , 'Scanned1.jpg'), image1)\n",
    "\t\t\t\t\n",
    "\t\tif(crop_morphology('clahe_2_blur_blur.jpg')):\t\n",
    "\n",
    "\t\t\timage=cv2.imread(\"clahe_2_blur_blur.crop.png\")\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tret1,image2 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "\t\t\tcv2.imwrite(os.path.join(dirname,'Scanned2.jpg'),image2)\n",
    "\n",
    "\t\tif(crop_morphology('clahe_2_sharp_blur.jpg')):\n",
    "\t\t\timage=cv2.imread(\"clahe_2_sharp_blur.crop.png\")\n",
    "\t\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tret1,image3 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "\t\t\tcv2.imwrite(os.path.join(dirname,'Scanned3.jpg'),image3)\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repo contains an introduction to [Jupyter](https://jupyter.org) and [IPython](https://ipython.org).\n",
    "\n",
    "Outline of some basics:\n",
    "\n",
    "* [Notebook Basics](../examples/Notebook/Notebook%20Basics.ipynb)\n",
    "* [IPython - beyond plain python](../examples/IPython%20Kernel/Beyond%20Plain%20Python.ipynb)\n",
    "* [Markdown Cells](../examples/Notebook/Working%20With%20Markdown%20Cells.ipynb)\n",
    "* [Rich Display System](../examples/IPython%20Kernel/Rich%20Output.ipynb)\n",
    "* [Custom Display logic](../examples/IPython%20Kernel/Custom%20Display%20Logic.ipynb)\n",
    "* [Running a Secure Public Notebook Server](../examples/Notebook/Running%20the%20Notebook%20Server.ipynb#Securing-the-notebook-server)\n",
    "* [How Jupyter works](../examples/Notebook/Multiple%20Languages%2C%20Frontends.ipynb) to run code in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get this tutorial and run it on your laptop:\n",
    "\n",
    "    git clone https://github.com/ipython/ipython-in-depth\n",
    "\n",
    "Install IPython and Jupyter:\n",
    "\n",
    "with [conda](https://www.anaconda.com/download):\n",
    "\n",
    "    conda install ipython jupyter\n",
    "\n",
    "with pip:\n",
    "\n",
    "    # first, always upgrade pip!\n",
    "    pip install --upgrade pip\n",
    "    pip install --upgrade ipython jupyter\n",
    "\n",
    "Start the notebook in the tutorial directory:\n",
    "\n",
    "    cd ipython-in-depth\n",
    "    jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
